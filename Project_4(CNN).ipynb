{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fpcUbDWv35R"
      },
      "outputs": [],
      "source": [
        "import cv2  # أو from PIL import Image إذا كنت تستخدم Pillow\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RNN, SimpleRNN\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import LambdaCallback\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datetime import date\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cH4VIjkEw5AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist # هذه داتاسيت جاهزة\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "GP9xr4YH0aJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "aFcfREJ91NtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/Gender/Taining'\n",
        "validation_dir ='/content/Gender/Testing'\n",
        "\n",
        "\n",
        "image_size = (100, 100)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNuLRieK187g",
        "outputId": "7abb888a-6ec7-49e5-991e-888101437c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.image_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrlj20cu4jAp",
        "outputId": "0e1272b6-7b2d-4d71-bb47-a0e722469461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "g-OFfusY2Aqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
      ],
      "metadata": {
        "id": "AqDGy-y16jlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "CoY-xOGv3a2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "#model.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "JfNgu-GV3dut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "#model.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "bunMAfM93ga1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "V-_TGzmj3jOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(50, activation='relu'))"
      ],
      "metadata": {
        "id": "6e93QKQ43lv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "QBsa_LL-3oP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PeAykNOD3q3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, validation_data=validation_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsBz4Tr93vTH",
        "outputId": "469e5508-9ad6-4252-fef6-0d26c2cacf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 4s 253ms/step - loss: 0.7109 - accuracy: 0.5467 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 3s 261ms/step - loss: 0.6297 - accuracy: 0.6367 - val_loss: 0.4729 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 0.5572 - accuracy: 0.7233 - val_loss: 0.4047 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 3s 281ms/step - loss: 0.5117 - accuracy: 0.7567 - val_loss: 0.2509 - val_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 3s 268ms/step - loss: 0.4834 - accuracy: 0.7733 - val_loss: 0.2629 - val_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 3s 287ms/step - loss: 0.4885 - accuracy: 0.7867 - val_loss: 0.2335 - val_accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 3s 273ms/step - loss: 0.4556 - accuracy: 0.7600 - val_loss: 0.1656 - val_accuracy: 0.9500\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.4718 - accuracy: 0.7733 - val_loss: 0.1428 - val_accuracy: 0.9500\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 4s 338ms/step - loss: 0.4093 - accuracy: 0.8100 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 3s 265ms/step - loss: 0.4176 - accuracy: 0.8267 - val_loss: 0.1064 - val_accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab800508b80>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F3TPFOU36q6",
        "outputId": "beaa8dc8-6a7a-44fa-e46d-f55cf68f2e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1064 - accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluation[1]\n",
        "loss = evaluation[0]"
      ],
      "metadata": {
        "id": "VjOouHHu4N6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Validation Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAiMXJYS4UCv",
        "outputId": "194260fc-1ee7-483e-d52c-4023ed9cf234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8000\n",
            "Validation Loss: 0.4400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Gender.zip"
      ],
      "metadata": {
        "id": "UWiZwFEUyHPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import cv2"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZCeWEXlgzvOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "4sydbiY-2KQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))"
      ],
      "metadata": {
        "id": "dwSbt_u12NhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#adding convolution layer\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "\"\"\"\n",
        "عدد الفلاتر 32 مجموع و انا اخترت الرقم يعني ابغى استخدم الفلاتر كلها\n",
        "وكل فلتر حجم  size اخترته حقه 3*3\n",
        "- Conv2D = Convolutional layer\n",
        "- input_shape=(28, 28, 1): يحدد شكل المدخلات المتوقع للنموذج.\n",
        "في هذه الحالة، يتوقع النموذج صورًا ذات أبعاد 28x28 وقناة واحدة (أبيض وأسود)، وهو ما يعني أن الصور ستكون ثنائية الأبعاد.\n",
        "\"\"\"\n",
        "#adding pooling layer\n",
        "model.add(MaxPool2D(2,2))# (2,2)حجم الماتريكس اللي بيقلصها\n",
        "\n",
        "\n",
        "#adding fully connected layer.... , 1dim vectorsتحويل البيانات المتعددة الأبعاد إلى بيانات متسطحة (بيانات ذات بُعد واحد)\n",
        "model.add(Flatten())\n",
        "\n",
        "#لان كل صورة صارت في  1 vector\n",
        "#بياخذ 32 vectors من 60000\n",
        "# رقم 32 ثابت دائماً\n",
        "model.add(Dense(100,activation='relu')) # 100 عدد النيورنز اللي بتطلع\n",
        "#adding output layer\n",
        "model.add(Dense(10,activation='softmax')) # 10 عدد الاوتبوت اللي بتطلع\n",
        "#compiling the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy']) #optimizer='adam' غالبا نستخدمه لانه يعطي نتايج افضل\n",
        "#fitting the model\n",
        "model.fit(X_train,y_train,epochs=10) #60000/32 = 1875 , وحددنا epochs=10 وهي عدد iteration"
      ],
      "metadata": {
        "id": "4p0Kde9Rzvi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install opencv-python"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UtAgPXmzsgk",
        "outputId": "d53eae59-b416-4065-d5c8-89e80cbf2d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = Path(\"/kaggle/input/rsna-breast-cancer-detection/train_images\")\n",
        "test_images = Path(\"/kaggle/input/rsna-breast-cancer-detection/test_images\")\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "Tnz9pGoE0wOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}